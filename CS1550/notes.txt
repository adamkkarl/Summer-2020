5/21/2020
CPU
1. What is a process?
2. How does context switching happen?
3. How does scheduling happen?
4. Bugs due to processes sharing a CPU

process - a program that's running
  has memory files, registers, process id (pid)
  
Process Control Block (PCB)
  (linux: task control block)
  pointer to process memory
  process state (running, waiting, etc)
  program counter and CPU registers
  CPU scheduling info
  memory management info
  accounting info (CPU used, clock time elapsed, etc)
  I/O status info

Context switching
1. CPU stores registers in old PCB
2. CPU reads registers from new PCB
  instructions ~1e-9s  mem access ~1e-6s
  so context switching has significant overhead

Scheduling
process state - is processs ready to run? waiting for network packet?
new, ready (in queue), running, waiting (on I/O or event), terminated

Schedulers
Short-term scheduler (CPU scheduler)
  selects next process and allocates CPU
  invoked frequently (ms) - must be fast
Long-term scheduler
  selects process to bring to queue
  infrequent (sec/min) - can be slow
  controls degree of multiprograming (processes in memory)
Medium-term scheduling
  when too many processes fill memory
  *swap* some out to disk temporarily

Queueing diagram
-> ready queue -> CPU ->
  -> terminate
  -> I/O request -> I/O queue -> I/O -> ready queue
  -> time slice expires -> ready queue
  -> fork a child -> child executes -> ready queue
  -> wait for interrupt -> interrupt occur -> ready queue

5/26/2020
fork - system call that creates a process
child gets new PCB
  knows pid of parent and copy of all parent's registers
child gets copy of parent's memory

fork() writes eax register to return a value
  parent: fork() returns pid of child
  child: fork() returns 0

ret = fork();
if (ret>0) {...parent code...}
if (ret==0){...child code...}

copy_on_write - setting to avoid overhead from forking
  only copies parent memory to child process memory if necessary
  NO memory copy on fork
  useful since often child process is completely different
    (ex: command line -> java runtime)

Process Creation
parent processes create children processes, creating tree
process identifier (pid) - identifies and manages processes
Resource sharing options:
  -parent and child chare all resources
  -children share subset (code, data, heap) of parent resources
  -parent and child share no resorces
Execution options
  -parent and child concurrent
  -parent wait()'s until children terminate

busy waiting/spinning - executing a long loop of nothing
  for(int i=0; i<10000000000; i++)

Orphan Process
  child with terminated parent
  gets adopted by OS process (id=1)

Zombie Process
  terminated process with parent still running
  process stays alive until parent wait()'s for it
  Bad - will take up memory until parent collects or orphans it

Process Termination
  parent can abort() a child if needed

5/28/2020
ThreadTest.java
for(int i=0; i<3; i++) {
  pthread_create(&tid[i], &attr, runner, (void *)((long long) i));
}
  //thread - children share heap/code/global vars of parent

void *runner(void *param) {
  int i = ((int)param);
  printf("%d param = %d\n", (int)tid[i], i);
  sum[i] = 0;
  for (int j=1; j<=n; j++) 
    sum[i] += j;
  pthread_exit(0);
}

Multiprocessing Bugs

Bounded Buffer Problem
  Circle Queue
  Producer process - adds to queue, increments size
  Consumer process - removes from queue, decrements size
Problem: Race Conditions
updating memory is not atomic (uninterruptable)

When it works
x==3
P1	P2
R1<=x		load
R1=R1+1		change
R1=>x		store
	R3<=x	load
	R3=R3+1	change
	R3=>x	store
x==5

When it gets interrupted (BUG)
x==3
P1	P2
R1<=x		load
	R3<=x	load
	R3=R3+1	change
R1=R1+1		change
R1=>x		store
	R1=>x	store
x==4

1 thread at a time:
private synchronized void addSum (Integer sum)
  sums.add(sum);

Critical Regions
  used to procide *mutual exclusion* and help fix race conditions
4 conditions for mutual exclusion
  1. No 2 processes simultaneously in critical region
  2. No assumptions about the speeds or number of CPUs
  3. No process outside of critical region can block another process
  4. No process must wait forever to enter its critical region

Busy Waiting: Strict Alternation
Use shared variable (turn) to keep track of whose turn
Continuously spins reading variable until it sees it can procede (spin lock)
Avoids race conditions, but fails #3 if critical region finishes, but interrupts before changes turn value

*Doesn't work with modern out-of-order compilers, might increment turn before critical region executes

Busy Waiting: Working Solution
void enter_region(int process) {
  int turn; //whose turn is it
  int interested[N]; //set to TRUE if process j is interested
  while (turn==other && interested[other]==TRUE) //solves #3 criteria
    ;
{

void leave_region(int process)
  interested[process] = FALSE;

Hardware for Synchronization
software sync works, but may be complex and busy waiting wastes CPU time
methods:
  Test and Sit - test variable and set it in 1 clock cycle
  Atomic Swap - swap register and memory in 1 clock cycle
  Turn off interrupts - disable interrupts during critical section
    dangerous: can hijack CPU

int lock = 0; //lock open

TEST AND SET
while (TestAndSet(lock))
  ;
//critical section
lock = 0
//noncritical section

SWAP
while(Swap(lock, 1) == 1)
  ;
//critical section
lock = 0;
//noncritical section

Basically if lock==0, first come first serve for critical section
Possible requirements issue -> can have unbounded waiting

Eliminating Busy Waiting
both harware and software solutions require wasteful spin locks

spin locking efficient if:
  1. multi-core CPU (might unlock before process gets rotated out)
  2. short critical section
  3. few contending processes

Priority Inversion
when a high priority process has to wait on a low priority process
solution: *semaphores*
Down(S): while (S<=0) {}; S-=1;  //also called P()
Up(S): S+=1;			 //also called V()

Shared variable: Semaphore mutex; //initialize to 1
	Pi
while(1) {
  down(mutex);
  //CS
  Up(mutex);
  //noncrit
}

SEMAPHORE CODE
class Semaphore {
  int val;
  ProcessList p1;
  void down();
  void up();
};

Semaphore::down() {
  //lock()
  val-=1
  if(val<0)
    //add process to p1
    //unlock()
    sleep()
}

Semaphore::up() {
  Process p;
  //lock()
  val += 1;
  if (val<=0)
    //remove process p from p1
  wakeup(p)
  //unlock()
}

Semaphore Metaphor
line of people to write on board, 3 markers (S=3)
or
red/green light at train junction where 1 gets through at a time (S=1)

6/2
Critical Section Problem Approaches
  1. Taking turns - user level software
  2. Atomic hardware instructions - spin locking
  3. Semaphores - needs OS support

Process calls down/wait/P on semaphore S to enter critical section
  -may block
  -may continue executing
  -may become ready for execution
  -requires OS support to take over and carry out system call

Semaphores for synchronization
Goal: execute B on P1 after A on P0

shared vars
Semaphore flag = 0; //flag starts down

P0
//execute A
flag.up()

P1
flag.down() //cannot happen until A puts flag up
//execute B

Types of Semaphores
Binary Semaphores S=0 or 1
Counting Semaphores S=2+

Deadlock and Starvation
Deadlock - 2+ processes waiting for another waiting process
  P0 has A, needs B
  P1 has B, needs A
  each waiting for the other
  might only happen extremely infrequently when context switches on exact line

Starvation - system making process, but low prio process waits indefinitely since it keeps getting jumped in line

MONITORS
monitor - another high-level sync primitive
  -enforces mutual exlusion
  -only 1 process in monitor at a time
  -implemented by the language/compiler, can also be implemented with semaphores
  -Java: public synchronized class MyClass {...}
    -all Java Objects (string, int, etc) are monitors (toString(), equals(), wait(), notify() are critical)

P0
myMon.proc1();
P1
myMon.proc2();
one will execute, other cannot start until first is done

How can a process wait inside a monitor?
  -cannot sleep, would block others from entering
  -Soln: use condition variable

Condition Variables: support 2 ops
  wait(): suspend process until signaled
  signal(): wake up 1 process waiting on condition variable (if any)
condition variables are only usable withing monitors

When signaling process P0 signals waiting process P1
  -Mesa semantics: P0 continues running
  -Hoare semantics: P1 runs within monitor
    can be implemented with semaphores
    useful when condition P1 waited on might not still be true once P0 leaves monitor

P0: m.f1();
P1: m.f2();
Monitor
int x=0;
Cv cv;
f1() {x=1; cv.signal(); x=0;}
f2() {while(x==0) cv.wait(); ...(rest assumes x!=0)
  must use while loop in Mesa semantics, otherwise wakes when x=1 but runs when x=0

Locks and Condition Variables
monitors require native language support
  -locks need acquire(), release() to enter/exit monitor
  -CVs need wait(), signal()

Condition Variable Usage
  each CV is associated with 1 lock
  lock must be helpd to use CV
  waiting on CV releases lock implicitly
  returning from wait() on CV reacquires the lock

Implementing lock using Semaphores (but not CV support)
  Hoare semantics (Mesa needs wait() syscall)

class Lock {
  Semaphore mutex(1); //lock open (1), closed (0)
  Semaphore next(0);
  int nextCount = 0;
};

Lock::Acquire() {mutex.down();}

Lock::Release() {
  if(nextCount > 0) //if something's waiting on lock
    next.up() //give lock to next
  else
    mutex.up() //open lock
}

every method in monitor needs to have
f1() {
  l.acquire();
  ...
  l.release();
}


Quiz 6/6 
The operating system continuously runs on the CPU and is always resident in memory: FALSE
With modern hardware and out-of-order execution with multipple cores, it's possible to solve Critical Section problems with software alone: FALSE
Assuming lock is a shared int, starting with lock==0, if 2 processes concurrently execute TestAndSet(lock) they will both get 1 as a return val: FALSE
A shared int that's used to implement a spinlock using TestAndSet should be initialized to 0,whereas a semaphore used to implement sleeplock should be initialized to 1: TRUE
When the following runs, fork will be called a total of 4 times:
  int main() {fork(); fork(); fork(); fork();} : FALSE
Copy-on-Write is a mechanism that avoids unneccessary memory copying when fork() is immediately followed by exec() in the child process: TRUE
All processes createdd using fork() have a process ID of 0: FALSE
Zombie processes waste system resources because the operating system does not free up their resources until their parents wait() on them: TRUE
On a single-core system, since the CPU can do only one thing at a time, there is no need to protect shared data in a multi-process application: FALSE
The code below is free from race conditions since every access to the shared variable x is surrounded by a lock/unlock pair
  int x=0;
  Lock l;
  l.acquire();
  if (x==0) {
    l.release();
    l.acquire();
    x++;
  }
  l.release();
  FALSE **
Each running thread has its own register set and stack: TRUE
A CPU-bounded process may not issue any input/output operations: FALSE
Threads are cheaper to context switch than processes: TRUE
In a single-core system, it is safe to assume that mutual exclusion is guaranteed when interrupts are disabled around a critical section: FALSE **
The stack of a thread can be corrupted by a thread of another process: FALSE
System calls change the privelege mode of the processor: TRUE
Microkernel operating systems are faster then monolithic systems: FALSE
Threads are cheaper to create than processes: TRUE
Consider parent Process P forks child process C. When P terminates, C becomes a zombie: FALSE
Which is not part of the OS: interrupt service routines, system call implementations, interrupt descriptor table, system call table, INTERRUPT DESCRIPTOR TABLE REGISTER

